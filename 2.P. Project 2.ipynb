{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "  \n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "abalone = fetch_ucirepo(id = 1)\n",
    "print(abalone.variables)\n",
    "\n",
    "data = abalone.data.original.to_numpy()\n",
    "\n",
    "# Getting rid of observations with 0 height, or with a height too large (as specified in the first report)\n",
    "data = data[data[:, 3] != 0]\n",
    "data = data[data[:, 3] < 0.5]\n",
    "        \n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -\n",
    "# 1. Regression (part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Data preparation\n",
    "> **Exercise**\n",
    "> \n",
    "> Explain what variable is predicted based on which other variables and what you hope to accomplish by the regression. \n",
    "> Mention your feature transformation choices such as one-of-K coding. \n",
    "> Since we will use regularization momentarily, apply a feature transformation to your data matrix X such that each column has mean $0$ and standard deviation $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. One-hot encoding\n",
    "We decided to use the one-hot encoding to transform the first attribute, which is the gender of the abalone: intially assuming values 'M', 'F', and 'I' for male, female, and infant, we encode the values by replacing the column with three different columns, one for each gender, in which the values are 1 if the original value was the gender, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sex_column(data):\n",
    "    # Extract sex column\n",
    "    sex_column = data[:, 0]\n",
    "    \n",
    "    # convert to 0 and 1\n",
    "    male = (sex_column == 'M').astype(int)\n",
    "    female = (sex_column == 'F').astype(int)\n",
    "    infant = (sex_column == 'I').astype(int)\n",
    "    \n",
    "    # Stack horizontally\n",
    "    encoded = np.column_stack((male, female, infant))\n",
    "    \n",
    "    # Combine with rest of data (excluding original sex column)\n",
    "    encoded_data = np.column_stack((encoded, data[:, 1:]))\n",
    "    \n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Data standardization\n",
    "We also need to standardize the data to have mean 0 and standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(data):\n",
    "    # Keep one-hot encoded columns unchanged\n",
    "    encoded_cols = data[:, :3]\n",
    "    \n",
    "    # Standardize remaining columns\n",
    "    numeric_cols = data[:, 3:].astype(float)\n",
    "    \n",
    "    # Calculate mean and std for each column\n",
    "    means = np.mean(numeric_cols, axis=0)\n",
    "    stds = np.std(numeric_cols, axis=0)\n",
    "    \n",
    "    # Standardize: (X - mean) / std\n",
    "    standardized_cols = (numeric_cols - means) / stds\n",
    "    \n",
    "    # Combine back with encoded columns\n",
    "    standardized_data = np.column_stack((encoded_cols, standardized_cols))\n",
    "    \n",
    "    return standardized_data, means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encode_sex_column(data)\n",
    "standardized_data, _, _ = standardize_data(encoded_data)\n",
    "X, y = standardized_data[:, :-1], standardized_data[:, -1:]\n",
    "\n",
    "print(f'Input:\\n{X}\\n\\nOutput:\\n{y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4. Linear regression\n",
    "We now implement a basic linear regression model that can solve analytically for the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.astype(np.float64)\n",
    "        self.y = y.astype(np.float64)\n",
    "        \n",
    "        self.weights = None\n",
    "        \n",
    "    def solve_analytical(self):\n",
    "        XtX = np.dot(self.X.T, self.X)\n",
    "        Xty = np.dot(self.X.T, self.y)\n",
    "        \n",
    "        self.weights = np.linalg.solve(XtX, Xty)\n",
    "        \n",
    "    def predict(self):\n",
    "        return np.dot(self.X, self.weights)\n",
    "    \n",
    "    def score(self):\n",
    "        y_pred = self.predict()\n",
    "        \n",
    "        ss_total = np.sum((self.y - np.mean(self.y)) ** 2)\n",
    "        ss_residual = np.sum((self.y - y_pred) ** 2)\n",
    "        r2 = 1 - (ss_residual / ss_total)\n",
    "        \n",
    "        mse = np.mean((self.y - y_pred) ** 2)\n",
    "        \n",
    "        return {'R2': r2, 'MSE': mse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(X, y)\n",
    "model.solve_analytical()\n",
    "scores = model.score()\n",
    "\n",
    "print(f\"R² Score: {scores['R2']:.4f}\")\n",
    "print(f\"MSE: {scores['MSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 1.2. Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Analytical solution\n",
    "First we have to update the method that solves the linear system to include the regularization term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_analytical(self, lambda_=0.0):\n",
    "    n_features = X.shape[1]\n",
    "    identity = np.eye(n_features)\n",
    "    \n",
    "    XtX = np.dot(self.X.T, self.X)\n",
    "    XtX_reg = XtX + lambda_ * identity\n",
    "    Xty = np.dot(self.X.T, self.y)\n",
    "    \n",
    "    self.weights = np.linalg.solve(XtX_reg, Xty)   \n",
    "    \n",
    "LinearRegression.solve_analytical = solve_analytical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(X, y)\n",
    "model.solve_analytical(lambda_=10)\n",
    "scores = model.score()\n",
    "\n",
    "print(f\"R² Score: {scores['R2']:.4f}\")\n",
    "print(f\"MSE: {scores['MSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Regularization path\n",
    "Then we can write a method for plotting the mean coefficient values, which shows the weights of each feature as a function of the regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regularization_effects(self, lambda_range, n_samples):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "    \n",
    "    lambdas = np.logspace(lambda_range[0], lambda_range[1], n_samples) \n",
    "\n",
    "    # Plot 1: Regularization Path\n",
    "    paths = []\n",
    "    for lambda_ in lambdas:\n",
    "        self.solve_analytical(lambda_)\n",
    "        paths.append(self.weights.flatten())\n",
    "    \n",
    "    paths = np.array(paths)\n",
    "    for i in range(paths.shape[1]):\n",
    "        ax1.semilogx(lambdas, paths[:, i], '-', label=f'Feature {i + 1}')\n",
    "    \n",
    "    ax1.set_xlabel('λ (Regularization Parameter)')\n",
    "    ax1.set_ylabel('Weight Value')\n",
    "    ax1.set_title('Weight Values vs Regularization λ')\n",
    "    ax1.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Plot 2: Model Performance\n",
    "    r2_scores = []\n",
    "    mse_scores = []\n",
    "    for lambda_ in lambdas:\n",
    "        self.solve_analytical(lambda_)\n",
    "        scores = self.score()\n",
    "        r2_scores.append(scores['R2'])\n",
    "        mse_scores.append(scores['MSE'])\n",
    "    \n",
    "    # Plot R² score\n",
    "    ax2.semilogx(lambdas, r2_scores, 'b-', label='R² Score')\n",
    "    ax2.set_xlabel('λ (Regularization Parameter)')\n",
    "    ax2.set_ylabel('R² Score', color='b')\n",
    "    ax2.tick_params(axis='y', labelcolor='b')\n",
    "    \n",
    "    # Plot MSE on secondary y-axis\n",
    "    ax3 = ax2.twinx()\n",
    "    ax3.semilogx(lambdas, mse_scores, 'r-', label='MSE')\n",
    "    ax3.set_ylabel('Mean Squared Error', color='r')\n",
    "    ax3.tick_params(axis='y', labelcolor='r')\n",
    "    \n",
    "    # Add legend\n",
    "    lines1, labels1 = ax2.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax3.get_legend_handles_labels()\n",
    "    ax3.legend(lines1 + lines2, labels1 + labels2, loc='center right')\n",
    "    \n",
    "    ax2.set_title('Model Performance vs Regularization')\n",
    "    ax2.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "    \n",
    "    \"\"\" fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "    # Regularization Path Plot\n",
    "    paths = []\n",
    "    for lambda_ in lambdas:\n",
    "        self.solve_analytical(lambda_)  # Assuming this function calculates self.weights\n",
    "        paths.append(self.weights.flatten())\n",
    "\n",
    "    # Convert to a NumPy array for easier indexing\n",
    "    paths = np.array(paths)\n",
    "\n",
    "    # Plot the weight paths for each feature\n",
    "    for i in range(paths.shape[1]):\n",
    "        ax.semilogx(lambdas, paths[:, i], '-', label=f'Feature {i + 1}')\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('λ (Regularization Parameter)')\n",
    "    ax.set_ylabel('Weight Value')\n",
    "    ax.set_title('Weight Values vs Regularization λ')\n",
    "    ax.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show() \"\"\"\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "LinearRegression.plot_regularization_effects = plot_regularization_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(X, y)\n",
    "fig = model.plot_regularization_effects(lambda_range=(-3, 6), n_samples=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Cross-validation and general estimated error\n",
    "The next step is to use the K-fold cross-validation to estimate the general error of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_level_cross_validation(self, lambda_, K=10):\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "    \n",
    "    mse_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(self.X):\n",
    "        X_train, X_test = self.X[train_index], self.X[test_index]\n",
    "        y_train, y_test = self.y[train_index], self.y[test_index]\n",
    "        \n",
    "        fold_model = LinearRegression(X_train, y_train)\n",
    "        fold_model.solve_analytical(lambda_)\n",
    "        \n",
    "        y_pred = np.dot(X_test, fold_model.weights)\n",
    "        \n",
    "        mse = np.mean((y_test - y_pred) ** 2)\n",
    "        \n",
    "        mse_scores.append(mse)\n",
    "        \n",
    "        \n",
    "    generalization_error = np.mean(mse_scores)\n",
    "    \n",
    "    return generalization_error\n",
    "\n",
    "LinearRegression.one_level_cross_validation = one_level_cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_level_cv_generalization_error(self, lambda_range=(-3, 6), num_lambdas=50, K=10):\n",
    "    generalization_errors = [{\n",
    "        'lambda': lambda_,\n",
    "        'err': self.one_level_cross_validation(lambda_, K),   \n",
    "    } for lambda_ in np.logspace(lambda_range[0], lambda_range[1], num_lambdas)]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    opt_lambda = 1000\n",
    "    lowest_mse = 1000\n",
    "    \n",
    "    for i in generalization_errors:\n",
    "        if i['err'] < lowest_mse:\n",
    "            lowest_mse = i['err']\n",
    "            opt_lambda = i['lambda']\n",
    "    print(f'Optimal lambda: {opt_lambda}')\n",
    "    print(f'Lowest MSE: {lowest_mse}')\n",
    "    \n",
    "    ax.semilogx([r['lambda'] for r in generalization_errors], [r['err'] for r in generalization_errors], '-')\n",
    "    ax.set_xlabel('lambda')\n",
    "    ax.set_ylabel('Generalization error')\n",
    "    ax.set_title('Generalization error vs. lambda')\n",
    "    \n",
    "    return fig\n",
    "        \n",
    "LinearRegression.plot_one_level_cv_generalization_error = plot_one_level_cv_generalization_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(X, y)\n",
    "fig = model.plot_one_level_cv_generalization_error()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "import pandas as pd\n",
    "\n",
    "X_shap, y_shap = standardized_data[:, :-1], standardized_data[:, -1:]\n",
    "y_shap = pd.Series(y_shap[:,0])\n",
    "\n",
    "feature_names = ['Male', 'Female', 'Infant'] + abalone.variables.name.to_numpy()[1:-1].tolist()\n",
    "#X_shap, y_shap = encoded_data[:, :-1], encoded_data[:, -1:]\n",
    "\n",
    "X_shap = pd.DataFrame(X_shap, columns=feature_names)\n",
    "for i in range(X_shap.shape[0]):\n",
    "    X_shap.values[i, 0] = float(X_shap.values[i, 0])\n",
    "    X_shap.values[i, 1] = float(X_shap.values[i, 1])\n",
    "    X_shap.values[i, 2] = float(X_shap.values[i, 2])\n",
    "    \n",
    "for i in range(X_shap.shape[0]):\n",
    "    for j in range(X_shap.shape[1]):\n",
    "        assert isinstance(X_shap.values[i, j], (float))\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_shap, y_shap, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "\n",
    "# a simple linear model\n",
    "model = LR()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fits the explainer\n",
    "explainer = shap.Explainer(model.predict, X_test)\n",
    "# Calculates the SHAP values - It takes some time\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Select only attributes 3 to 10 (zero-indexed: 2 to 9)\n",
    "selected_indices = slice(3, 10)  # This corresponds to columns 3 to 10\n",
    "\n",
    "# Get the relevant SHAP values and feature names\n",
    "shap_values_subset = shap_values[:, selected_indices]\n",
    "X_test_subset = X_test.iloc[:, selected_indices]\n",
    "\n",
    "# Plot SHAP values for the selected features\n",
    "shap.summary_plot(shap_values_subset, X_test_subset, feature_names=X_test.columns[selected_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def print_feature_importances_shap_values(shap_values, features):\n",
    "    # Calculates the feature importance (mean absolute shap value) for each feature\n",
    "    importances = []\n",
    "    for i in range(shap_values.values.shape[1]):\n",
    "        importances.append(np.mean(np.abs(shap_values.values[:, i])))\n",
    "        \n",
    "    # Calculates the normalized version\n",
    "    importances_norm = softmax(importances)\n",
    "    \n",
    "    # Organize the importances and columns in a dictionary\n",
    "    feature_importances = {fea: imp for imp, fea in zip(importances, features)}\n",
    "    feature_importances_norm = {fea: imp for imp, fea in zip(importances_norm, features)}\n",
    "    \n",
    "    # Sorts the dictionary\n",
    "    feature_importances = {k: v for k, v in sorted(feature_importances.items(), key=lambda item: item[1], reverse = True)}\n",
    "    feature_importances_norm= {k: v for k, v in sorted(feature_importances_norm.items(), key=lambda item: item[1], reverse = True)}\n",
    "    \n",
    "    # Prints the feature importances\n",
    "    for k, v in feature_importances.items():\n",
    "        print(f\"{k} -> {v:.4f}\")\n",
    "\n",
    "print_feature_importances_shap_values(shap_values, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 1.3. Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. \n",
    "Explain how the output, $y$, of the linear model with the lowest generalization error (as determined in the previous question) is computed for a given input $x$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2. \n",
    "What is the effect of an individual attribute in $x$ on the output, $y$, of the linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3. \n",
    "Does the effect of individual attributes make sense based on your understanding of the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -\n",
    "\n",
    "# 2. Regression (part 2)\n",
    "\n",
    "In this section, we will compare three models: the regularized linear regression model from the previous section, an artificial neural network (ANN) and a baseline. We are interested in two questions: Is one model better than the other? Is either model better than a trivial baseline?. We will attempt to answer these questions with two-level cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Building the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Baseline model\n",
    "\n",
    "As a baseline, we will use a linear regression model without features, that predicts the output for each test data always as the average of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_average(self, y):\n",
    "    return np.mean(y)\n",
    "    \n",
    "LinearRegression.predict_on_average = predict_on_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(X, y)\n",
    "pred = model.predict_on_average(y)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Artificial Neural Networks (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data, targets, batch_size=32, shuffle=True):\n",
    "        if isinstance(data, np.ndarray):\n",
    "            self.data = torch.FloatTensor(data)\n",
    "        else:\n",
    "            self.data = data\n",
    "            \n",
    "        if isinstance(targets, np.ndarray):\n",
    "            self.targets = torch.FloatTensor(targets)\n",
    "        else:\n",
    "            self.targets = targets\n",
    "            \n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_samples = len(data)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.index = 0\n",
    "\n",
    "        self.indices = list(range(self.n_samples))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.index >= self.n_samples:\n",
    "            raise StopIteration\n",
    "            \n",
    "        # Get indices for current batch\n",
    "        batch_indices = self.indices[self.index:min(self.index + self.batch_size, self.n_samples)]\n",
    "        \n",
    "        # Get data and targets for current batch\n",
    "        batch_data = self.data[batch_indices]\n",
    "        batch_targets = self.targets[batch_indices]\n",
    "        \n",
    "        self.index += self.batch_size\n",
    "        \n",
    "        return batch_data, batch_targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (self.n_samples + self.batch_size - 1) // self.batch_size\n",
    "    \n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNRegression(nn.Module):\n",
    "    def __init__(self, input_size, hidden_neurons):\n",
    "        super(ANNRegression, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_neurons)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_neurons, 1)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "    def train_(self, train_loader, test_loader, optimizer, criterion, num_epochs):\n",
    "        test_losses = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = self.predict(data)\n",
    "                \n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if batch_idx == train_loader.dataset.__len__():\n",
    "                    print(\n",
    "                        f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]',\n",
    "                        f'Loss: {loss.item():.6f}'\n",
    "                    )\n",
    "                    \n",
    "            self.eval()\n",
    "            test_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for data, target in test_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = self.predict(data)\n",
    "                    test_loss += criterion(output, target).item()\n",
    "                    \n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 2.2. Comparing the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Two-level cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 50\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def two_level_cross_validation(lambdas, hidden_neurons, outer_K, inner_K):\n",
    "    lr_outer_mse_scores = []\n",
    "    ann_outer_mse_scores = []\n",
    "    \n",
    "    outer_kf = KFold(n_splits=outer_K, shuffle=True, random_state=42)\n",
    "    outer_progress = tqdm(outer_kf.split(X), desc=\"Outer Fold\", total=outer_K)\n",
    "    \n",
    "    for outer_fold, (outer_train_index, outer_test_index) in enumerate(outer_progress):\n",
    "        X_outer_train, X_outer_test = X[outer_train_index], X[outer_test_index]\n",
    "        y_outer_train, y_outer_test = y[outer_train_index], y[outer_test_index]\n",
    "        \n",
    "        lr_lowest_inner_mse = np.inf\n",
    "        best_lambda = None\n",
    "        \n",
    "        ann_lowest_inner_mse = np.inf\n",
    "        best_hidden = None\n",
    "        \n",
    "        inner_kf = KFold(n_splits=inner_K, shuffle=True, random_state=42)\n",
    "        inner_progress = tqdm(inner_kf.split(X_outer_train), desc=f\"Outer Fold {outer_fold+1} - Inner Fold\", total=inner_K, leave=False)\n",
    "        \n",
    "        for i, (inner_train_index, inner_val_index) in enumerate(inner_progress):\n",
    "            X_inner_train, X_inner_val = X_outer_train[inner_train_index], X_outer_train[inner_val_index]\n",
    "            y_inner_train, y_inner_val = y_outer_train[inner_train_index], y_outer_train[inner_val_index]\n",
    "            \n",
    "            # Train the linear regression model\n",
    "            lambda_ = lambdas[i]\n",
    "            lr_model = LinearRegression(X_inner_train, y_inner_train)\n",
    "            lr_model.solve_analytical(lambda_)\n",
    "            lr_val_pred = np.dot(X_inner_val, lr_model.weights)\n",
    "            lr_inner_mse = np.mean((y_inner_val - lr_val_pred) ** 2)\n",
    "            if lr_inner_mse < lr_lowest_inner_mse:\n",
    "                lr_lowest_inner_mse = lr_inner_mse\n",
    "                best_lambda = lambda_\n",
    "                \n",
    "            # Train the ANN model\n",
    "            X_inner_train = torch.Tensor(X_inner_train.astype(np.float64)).to(device)\n",
    "            y_inner_train = torch.Tensor(y_inner_train.astype(np.float64)).to(device)\n",
    "            X_inner_val = torch.Tensor(X_inner_val.astype(np.float64)).to(device)\n",
    "            y_inner_val = torch.Tensor(y_inner_val.astype(np.float64)).to(device)\n",
    "            \n",
    "            train_loader = DataLoader(X_inner_train, y_inner_train, batch_size=batch_size)\n",
    "            val_loader = DataLoader(X_inner_val, y_inner_val, batch_size=batch_size)\n",
    "\n",
    "            hidden = hidden_neurons[i]\n",
    "            ann_model = ANNRegression(X_inner_train.shape[1], hidden)\n",
    "            ann_model.to(device)\n",
    "            optimizer = torch.optim.Adam(ann_model.parameters(), lr=1e-3)\n",
    "            \n",
    "            ann_model.train_(train_loader, val_loader, optimizer, criterion, num_epochs)\n",
    "            ann_val_pred = ann_model.predict(X_inner_val)\n",
    "            ann_inner_mse = np.mean((y_inner_val.cpu().detach().numpy() - ann_val_pred.cpu().detach().numpy()) ** 2)\n",
    "            if ann_inner_mse < ann_lowest_inner_mse:\n",
    "                ann_lowest_inner_mse = ann_inner_mse\n",
    "                best_hidden = hidden\n",
    "        \n",
    "        # Train the outer linear regression model with the best lambda\n",
    "        lr_model = LinearRegression(X_outer_train, y_outer_train)\n",
    "        lr_model.solve_analytical(best_lambda)\n",
    "        lr_test_pred = np.dot(X_outer_test, lr_model.weights)\n",
    "        lr_outer_mse = np.mean((y_outer_test - lr_test_pred) ** 2)\n",
    "        lr_outer_mse_scores.append({\n",
    "            'lambda': best_lambda,\n",
    "            'mse': lr_outer_mse\n",
    "        })\n",
    "        \n",
    "        # Train the outer ANN model with the best number of hidden neurons\n",
    "        X_outer_train = torch.Tensor(X_outer_train.astype(np.float64)).to(device)\n",
    "        y_outer_train = torch.Tensor(y_outer_train.astype(np.float64)).to(device)\n",
    "        X_outer_test = torch.Tensor(X_outer_test.astype(np.float64)).to(device)\n",
    "        y_outer_test = torch.Tensor(y_outer_test.astype(np.float64)).to(device)\n",
    "        \n",
    "        train_loader = DataLoader(X_outer_train, y_outer_train, batch_size=batch_size)\n",
    "        test_loader = DataLoader(X_outer_test, y_outer_test, batch_size=batch_size)\n",
    "\n",
    "        hidden = hidden_neurons[i]\n",
    "        ann_model = ANNRegression(X_outer_train.shape[1], hidden)\n",
    "        ann_model.to(device)\n",
    "        optimizer = torch.optim.Adam(ann_model.parameters(), lr=1e-3)\n",
    "        \n",
    "        ann_model.train_(train_loader, test_loader, optimizer, criterion, num_epochs)\n",
    "        ann_test_pred = ann_model.predict(X_outer_test)\n",
    "        ann_outer_mse = np.mean((y_outer_test.cpu().detach().numpy() - ann_test_pred.cpu().detach().numpy()) ** 2)\n",
    "        ann_outer_mse_scores.append({\n",
    "            'hidden': best_hidden,\n",
    "            'mse': ann_outer_mse\n",
    "        })\n",
    "        \n",
    "    return lr_outer_mse_scores, ann_outer_mse_scores\n",
    "\n",
    "lr_outer_mse_scores, ann_outer_mse_scores = two_level_cross_validation(\n",
    "    lambdas=np.logspace(-3, 6, 10), \n",
    "    hidden_neurons=[int(math.pow(2, i)) for i in range(10)],  \n",
    "    outer_K=10,\n",
    "    inner_K=10,\n",
    ")\n",
    "\n",
    "print(lr_outer_mse_scores)\n",
    "print(ann_outer_mse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Creating a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, we will use the same setup as the first project, so we will use the gender as the target variable, since it's categroical, and the number of rings as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Logistic regression for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, X, y, learning_rate=0.01, max_iterations=1000, tol=1e-4):\n",
    "        self.X = X.astype(np.float64)\n",
    "        self.y = y.astype(np.float64).reshape(-1, 1)  # Ensure y is a column vector\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.tol = tol\n",
    "        \n",
    "        # Initialize weights with proper shape\n",
    "        self.weights = np.zeros((X.shape[1], 1)) # Make weights a column vector\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))  # Clip to prevent overflow\n",
    "    \n",
    "    def fit(self):\n",
    "        m = len(self.y)  # number of samples\n",
    "        prev_loss = float('inf')\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            # Forward pass\n",
    "            z = np.dot(self.X, self.weights)  # Shape: (m, 1)\n",
    "            y_pred = self.sigmoid(z)  # Shape: (m, 1)\n",
    "            \n",
    "            # Compute loss (binary cross-entropy)\n",
    "            loss = -np.mean(\n",
    "                self.y * np.log(y_pred + 1e-15) + \n",
    "                (1 - self.y) * np.log(1 - y_pred + 1e-15)\n",
    "            )\n",
    "            \n",
    "            # Check convergence\n",
    "            if abs(prev_loss - loss) < self.tol:\n",
    "                print(f\"Converged after {iteration} iterations\")\n",
    "                break\n",
    "            prev_loss = loss\n",
    "            \n",
    "            if iteration % 100 == 0:\n",
    "                print(f\"Iteration {iteration}, Loss: {loss}\")\n",
    "            \n",
    "            # Compute gradients - shape will be (n_features, 1)\n",
    "            gradient = (1 / m) * np.dot(self.X.T, (y_pred - self.y))\n",
    "            \n",
    "            # Update weights - shapes match now\n",
    "            self.weights -= self.learning_rate * gradient\n",
    "    \n",
    "    def predict_probability(self, X=None):\n",
    "        if X is None:\n",
    "            X = self.X\n",
    "        return self.sigmoid(np.dot(X, self.weights))\n",
    "    \n",
    "    def predict(self, X=None, threshold=0.5):\n",
    "        probas = self.predict_probability(X)\n",
    "        return (probas >= threshold).astype(int)\n",
    "    \n",
    "    def score(self):\n",
    "        y_pred = self.predict()\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy = np.mean(y_pred == self.y)\n",
    "        \n",
    "        # Confusion matrix elements\n",
    "        tp = np.sum((y_pred == 1) & (self.y == 1))\n",
    "        tn = np.sum((y_pred == 0) & (self.y == 0))\n",
    "        fp = np.sum((y_pred == 1) & (self.y == 0))\n",
    "        fn = np.sum((y_pred == 0) & (self.y == 1))\n",
    "        \n",
    "        # Precision, Recall, F1\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        metrics = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1\n",
    "        }\n",
    "        \n",
    "        print(\"\\nMetrics:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "            \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(X, y)\n",
    "model.fit()\n",
    "model.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. ANN, KNN, NB or CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNClassification(nn.Module):\n",
    "    def __init__(self, input_size, hidden_neurons):\n",
    "        super(ANNClassification, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_neurons)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_neurons, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "    \n",
    "    def train_(self, train_loader, test_loader, optimizer, criterion, num_epochs):\n",
    "        test_losses = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = self.predict(data)\n",
    "                \n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if batch_idx == train_loader.dataset.__len__():\n",
    "                    print(\n",
    "                        f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]',\n",
    "                        f'Loss: {loss.item():.6f}'\n",
    "                    )\n",
    "                    \n",
    "            self.eval()\n",
    "            test_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for data, target in test_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = self.predict(data)\n",
    "                    test_loss += criterion(output, target).item()\n",
    "                    \n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        plt.plot(test_losses)\n",
    "        plt.title('Loss vs. epoch')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -\n",
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "The subplot that corresponds to the ROC curve is C, because decreasing the threshold starting from $1.0$, the first point that become predicted as poisitve is a true positive, so the ROC curve moves up, then we have two points that become predicted as positive, but are in fact false positives, so the ROC curve moves right twice, and so on, tracing the curve in the figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "The impurity gain of the split is $\\Delta\\approx 0.0148$, because:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Delta\n",
    "&=I(r)-\\displaystyle\\sum_{i=1}^K\\frac{N_i}{N}I(v_i)=\\\\\n",
    "&=\\left(1-\\dfrac{37}{37+31+33+34}\\right)-\\left[\\dfrac{120}{135}\\left(1-\\dfrac{33}{33+28+30+29}\\right)+\\dfrac{14}{135}\\left(1-\\dfrac5{4+2+3+5}\\right)+\\dfrac1{135}\\left(1-\\dfrac11\\right)\\right]=\\\\\n",
    "&=\\dfrac{98}{135}-\\left[\\dfrac{120}{135}\\dfrac{87}{120}+\\dfrac{14}{135}\\dfrac{9}{14}+\\dfrac{1}{135}\\cdot0\\right]=\\\\\n",
    "&=\\dfrac{98}{135}-\\dfrac{96}{135}=\\\\\n",
    "&=\\dfrac2{135}\\approx0.0148\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "The network contains $110$ parameters, because the input layer has $7$ neurons, the hidden layer has $10$ neurons, and the output layer has $4$ neurons, so the weights are $7\\times 10+10\\times 4=110$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "The correct rules assignment to the nodes are the ones described in D, because A separates $b_1<-0.76$ from $b_1>-0.76$, B separates the top-left region (congestion level 2) from the bottom-left region (congestion level 1), then C separates the right-most region (congestion level 4) from the middle strip, which is finally separated by D into middle-top (congestion level 1) and middle-bottom (congestion level 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "The observation assigned to class $y=4$ will be observation B, because:\n",
    "- $\\hat y_1=\\begin{bmatrix}1\\\\-0.6\\\\-1.6\\end{bmatrix}^T\\begin{bmatrix}1.2\\\\-2.1\\\\3.2\\end{bmatrix}=-2.66$\n",
    "- $\\hat y_2=\\begin{bmatrix}1\\\\-0.6\\\\-1.6\\end{bmatrix}^T\\begin{bmatrix}1.2\\\\-1.7\\\\2.9\\end{bmatrix}=-2.42$\n",
    "- $\\hat y_3=\\begin{bmatrix}1\\\\-0.6\\\\-1.6\\end{bmatrix}^T\\begin{bmatrix}1.3\\\\-1.1\\\\2.2\\end{bmatrix}=-1.56$\n",
    "\n",
    "So $P(y=4|\\hat{\\textbf{y}})=\\dfrac1{1+e^{-2.66}+e^{-2.42}+e^{-1.56}}\\approx0.74$ (being more than $0.5$ makes useless to calculate the probability of the other classes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
